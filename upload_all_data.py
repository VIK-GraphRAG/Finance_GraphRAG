#!/usr/bin/env python3
"""
ëª¨ë“  ë² ì´ìŠ¤ë¼ì¸ ë°ì´í„°ë¥¼ Neo4jì— ì˜êµ¬ ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
Upload all baseline data to Neo4j (persistent storage)

Features:
- OpenAI APIë¥¼ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ì—”í‹°í‹° ì¶”ì¶œ
- Neo4jì— ì˜êµ¬ ì €ì¥ (ì„¸ì…˜ ì¢…ë£Œ í›„ì—ë„ ìœ ì§€)
- ê·¸ë˜í”„ ì‹œê°í™” ì§€ì›
"""

import os
import sys
import json
import asyncio
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from db.neo4j_db import Neo4jDatabase
from config import NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD, OPENAI_API_KEY, OPENAI_BASE_URL

def upload_json_file(db: Neo4jDatabase, json_path: str):
    """JSON íŒŒì¼ì„ Neo4jì— ì—…ë¡œë“œ"""
    print(f"\nğŸ“¦ Processing: {json_path}")
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # supply_chain_mapping.json ì²˜ë¦¬
    if 'supply_chain' in data:
        supply_chain = data['supply_chain']
        tiers = supply_chain.get('tiers', [])
        
        nodes_created = 0
        relationships_created = 0
        
        for tier in tiers:
            tier_num = tier.get('tier')
            tier_name = tier.get('name')
            
            for company in tier.get('companies', []):
                company_name = company.get('name')
                
                # Company ë…¸ë“œ ìƒì„±
                query = """
                MERGE (c:Company {name: $name})
                SET c.tier = $tier,
                    c.tier_name = $tier_name,
                    c.role = $role,
                    c.criticality = $criticality,
                    c.location = $location
                RETURN c
                """
                
                db.execute_query(query, {
                    'name': company_name,
                    'tier': tier_num,
                    'tier_name': tier_name,
                    'role': company.get('role', ''),
                    'criticality': company.get('criticality', 'medium'),
                    'location': company.get('location', '')
                })
                nodes_created += 1
                
                # Dependencies (ê´€ê³„) ìƒì„±
                for dep in company.get('dependencies', []):
                    dep_query = """
                    MATCH (c1:Company {name: $company})
                    MERGE (c2:Company {name: $dependency})
                    MERGE (c1)-[r:DEPENDS_ON]->(c2)
                    RETURN r
                    """
                    
                    db.execute_query(dep_query, {
                        'company': company_name,
                        'dependency': dep
                    })
                    relationships_created += 1
        
        print(f"âœ… Created {nodes_created} nodes and {relationships_created} relationships")
        return nodes_created, relationships_created
    
    return 0, 0


async def upload_pdf_file_with_openai(pdf_path: str, db: Neo4jDatabase):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ PDFë¥¼ ì²˜ë¦¬í•˜ê³  Neo4jì— ì˜êµ¬ ì €ì¥
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        db: Neo4j ë°ì´í„°ë² ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print(f"\nğŸ“„ Processing PDF with OpenAI: {os.path.basename(pdf_path)}")
    
    try:
        import pymupdf
        from openai import AsyncOpenAI
        
        # 1. PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        doc = pymupdf.open(pdf_path)
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        
        if not text or len(text.strip()) < 10:
            print(f"âš ï¸ PDF contains no extractable text")
            return None
        
        print(f"  âœ… Extracted {len(text)} characters from PDF")
        
        # 2. OpenAIë¡œ ì—”í‹°í‹° ë° ê´€ê³„ ì¶”ì¶œ
        client = AsyncOpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
        
        chunk_size = 3000  # í° ì²­í¬ë¡œ ì²˜ë¦¬ (OpenAIëŠ” ì»¨í…ìŠ¤íŠ¸ê°€ í¬ë¯€ë¡œ)
        chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]
        
        # ìµœëŒ€ 30ê°œ ì²­í¬ë§Œ ì²˜ë¦¬ (ë¹„ìš© ì ˆê°)
        max_chunks = 30
        if len(chunks) > max_chunks:
            print(f"  âš ï¸ Limiting to first {max_chunks} chunks (out of {len(chunks)})")
            chunks = chunks[:max_chunks]
        
        all_entities = []
        all_relationships = []
        
        print(f"  ğŸ¤– Processing {len(chunks)} chunks with GPT-4o-mini...")
        
        for i, chunk in enumerate(chunks):
            if i > 0 and i % 5 == 0:
                print(f"    Progress: {i}/{len(chunks)} chunks ({i*100//len(chunks)}%)")
            
            prompt = f"""Extract business entities and relationships from this semiconductor/financial text.
Return ONLY valid JSON format:

{{
  "entities": [
    {{"name": "EntityName", "type": "COMPANY|PERSON|PRODUCT|TECHNOLOGY|FINANCIAL_METRIC|LOCATION|REGULATION|RISK", "properties": {{"key": "value"}}}}
  ],
  "relationships": [
    {{"source": "EntityA", "target": "EntityB", "type": "RELATIONSHIP_TYPE", "properties": {{"key": "value"}}}}
  ]
}}

Entity types: COMPANY, PERSON, PRODUCT, TECHNOLOGY, FINANCIAL_METRIC, LOCATION, REGULATION, RISK, MARKET, SUPPLY_CHAIN
Relationship types: SUPPLIES, PURCHASES, COMPETES_WITH, HAS_CEO, EMPLOYS, LOCATED_IN, PRODUCES, IMPACTS, DEPENDS_ON, REGULATES

Text:
{chunk[:3000]}

JSON output:"""
            
            try:
                response = await client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "You are a financial document analyzer. Extract structured entities and relationships. Respond with valid JSON only."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,
                    max_tokens=2000
                )
                
                content = response.choices[0].message.content.strip()
                
                # Parse JSON from response
                if content.startswith("```json"):
                    content = content[7:]
                if content.startswith("```"):
                    content = content[3:]
                if content.endswith("```"):
                    content = content[:-3]
                content = content.strip()
                
                extracted = json.loads(content)
                all_entities.extend(extracted.get("entities", []))
                all_relationships.extend(extracted.get("relationships", []))
                
            except Exception as e:
                print(f"    âš ï¸ Chunk {i} extraction failed: {e}")
                continue
        
        print(f"  âœ… Extracted {len(all_entities)} entities, {len(all_relationships)} relationships")
        
        # 3. Neo4jì— ì €ì¥
        from engine.integrator import DataIntegrator
        
        integrator = DataIntegrator()
        graph_data = {
            "entities": all_entities,
            "relationships": all_relationships
        }
        
        source_file = os.path.basename(pdf_path)
        source_label = Path(pdf_path).stem
        
        merge_stats = integrator.ingestPdfGraph(
            graphData=graph_data,
            sourceFile=source_file,
            sourceLabel=source_label
        )
        integrator.close()
        
        print(f"  âœ… Merged into Neo4j: {merge_stats.get('entitiesMerged', 0)} entities, {merge_stats.get('relationshipsCreated', 0)} relationships")
        
        return {
            'text_length': len(text),
            'entities_extracted': len(all_entities),
            'relationships_extracted': len(all_relationships),
            'merge_stats': merge_stats,
            'source_file': source_file
        }
    
    except Exception as e:
        print(f"  âŒ Error processing PDF: {e}")
        import traceback
        traceback.print_exc()
        return None


async def main_async():
    """ë©”ì¸ í•¨ìˆ˜ (ë¹„ë™ê¸°)"""
    print("=" * 70)
    print("ğŸš€ ë² ì´ìŠ¤ë¼ì¸ ë°ì´í„° Neo4j ì˜êµ¬ ì €ì¥ ì‹œì‘")
    print("=" * 70)
    
    # ì„¤ì • í™•ì¸
    if not NEO4J_URI or not NEO4J_PASSWORD:
        print("âŒ Neo4j ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    if not OPENAI_API_KEY:
        print("âŒ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    # Neo4j ì—°ê²°
    db = Neo4jDatabase(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)
    print(f"âœ… Neo4j ì—°ê²° ì„±ê³µ: {NEO4J_URI}")
    
    # ë°ì´í„° í´ë”
    data_dir = Path(__file__).parent / 'data' / 'baseline'
    
    if not data_dir.exists():
        print(f"âŒ ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
        sys.exit(1)
    
    # 1. JSON íŒŒì¼ ì—…ë¡œë“œ
    print("\n" + "=" * 70)
    print("ğŸ“¦ 1ë‹¨ê³„: JSON íŒŒì¼ ì—…ë¡œë“œ")
    print("=" * 70)
    
    json_files = list(data_dir.glob('*.json'))
    total_nodes = 0
    total_rels = 0
    
    for json_file in json_files:
        nodes, rels = upload_json_file(db, str(json_file))
        total_nodes += nodes
        total_rels += rels
    
    print(f"\nâœ… JSON ì—…ë¡œë“œ ì™„ë£Œ: {total_nodes} nodes, {total_rels} relationships")
    
    # 2. PDF íŒŒì¼ ì—…ë¡œë“œ (OpenAI API ì‚¬ìš©)
    print("\n" + "=" * 70)
    print("ğŸ“„ 2ë‹¨ê³„: PDF íŒŒì¼ ì—…ë¡œë“œ (OpenAI GPT-4o-mini ì‚¬ìš©)")
    print("=" * 70)
    
    pdf_files = list(data_dir.glob('*.pdf'))
    
    if not pdf_files:
        print("âš ï¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"ë°œê²¬ëœ PDF íŒŒì¼: {len(pdf_files)}ê°œ")
        for pdf in pdf_files:
            print(f"  - {pdf.name}")
        
        pdf_count = 0
        total_entities = 0
        total_relationships = 0
        
        for pdf_file in pdf_files:
            result = await upload_pdf_file_with_openai(str(pdf_file), db)
            if result:
                pdf_count += 1
                total_entities += result.get('entities_extracted', 0)
                total_relationships += result.get('relationships_extracted', 0)
        
        print(f"\nâœ… PDF ì—…ë¡œë“œ ì™„ë£Œ:")
        print(f"  - ì²˜ë¦¬ëœ íŒŒì¼: {pdf_count}/{len(pdf_files)}")
        print(f"  - ì¶”ì¶œëœ ì—”í‹°í‹°: {total_entities}")
        print(f"  - ì¶”ì¶œëœ ê´€ê³„: {total_relationships}")
    
    # 3. ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
    print("\n" + "=" * 70)
    print("ğŸ“Š 3ë‹¨ê³„: Neo4j ë°ì´í„°ë² ì´ìŠ¤ í†µê³„")
    print("=" * 70)
    
    # ë…¸ë“œ í†µê³„
    stats_query = """
    MATCH (n)
    RETURN labels(n)[0] as type, count(n) as count
    ORDER BY count DESC
    """
    
    stats = db.execute_query(stats_query)
    
    print("\në…¸ë“œ íƒ€ì…ë³„ ê°œìˆ˜:")
    total_node_count = 0
    for record in stats:
        count = record['count']
        total_node_count += count
        print(f"  - {record['type']}: {count:,}")
    print(f"  ğŸ“Š ì´ ë…¸ë“œ ìˆ˜: {total_node_count:,}")
    
    # ê´€ê³„ í†µê³„
    rel_query = """
    MATCH ()-[r]->()
    RETURN type(r) as type, count(r) as count
    ORDER BY count DESC
    """
    
    rel_stats = db.execute_query(rel_query)
    
    print("\nê´€ê³„ íƒ€ì…ë³„ ê°œìˆ˜:")
    total_rel_count = 0
    for record in rel_stats:
        count = record['count']
        total_rel_count += count
        print(f"  - {record['type']}: {count:,}")
    print(f"  ğŸ”— ì´ ê´€ê³„ ìˆ˜: {total_rel_count:,}")
    
    # ë°ì´í„° ì†ŒìŠ¤ë³„ í†µê³„
    source_query = """
    MATCH (n)
    WHERE n.source_file IS NOT NULL
    RETURN n.source_file as source, count(n) as count
    ORDER BY count DESC
    LIMIT 10
    """
    
    source_stats = db.execute_query(source_query)
    
    if source_stats:
        print("\nì†ŒìŠ¤ íŒŒì¼ë³„ ë…¸ë“œ ê°œìˆ˜ (Top 10):")
        for record in source_stats:
            print(f"  - {record['source']}: {record['count']:,}")
    
    db.close()
    
    print("\n" + "=" * 70)
    print("âœ… ëª¨ë“  ë°ì´í„° Neo4j ì˜êµ¬ ì €ì¥ ì™„ë£Œ!")
    print("   ì„¸ì…˜ ì¢…ë£Œ í›„ì—ë„ ë°ì´í„°ê°€ ìœ ì§€ë©ë‹ˆë‹¤.")
    print("   Streamlit UIì˜ Visualization íƒ­ì—ì„œ ê·¸ë˜í”„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    print("=" * 70)


def main():
    """ë™ê¸° ë˜í¼ í•¨ìˆ˜"""
    asyncio.run(main_async())


if __name__ == "__main__":
    main()
