#!/usr/bin/env python3
"""
Baseline PDF íŒŒì¼ë“¤ì„ Neo4jì— ì˜êµ¬ ì €ì¥
- ì„¸ì…˜ ì¢…ë£Œ í›„ì—ë„ ë°ì´í„° ìœ ì§€
- ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ í‘œì‹œ
- ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ê³„ì† ì§„í–‰
"""

import os
import sys
import json
import asyncio
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from db.neo4j_db import Neo4jDatabase
from config import NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD, OPENAI_API_KEY, OPENAI_BASE_URL


async def process_pdf_to_neo4j(pdf_path: Path, db: Neo4jDatabase):
    """
    ë‹¨ì¼ PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ Neo4jì— ì €ì¥
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“„ {pdf_path.name}")
    print(f"{'='*70}")
    
    try:
        import pymupdf
        from openai import AsyncOpenAI
        from engine.integrator import DataIntegrator
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size_kb = pdf_path.stat().st_size / 1024
        print(f"   ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size_kb:.1f} KB")
        
        # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ (íƒ€ì„ì•„ì›ƒ ì ìš©)
        print(f"   â³ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
        
        try:
            doc = pymupdf.open(str(pdf_path))
            text = ""
            page_count = len(doc)
            
            # í˜ì´ì§€ ìˆ˜ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì œí•œ
            max_pages = 200
            if page_count > max_pages:
                print(f"      âš ï¸ í˜ì´ì§€ ìˆ˜ ì œí•œ: {page_count} â†’ {max_pages}")
                page_count = max_pages
            
            for page_num in range(min(page_count, len(doc))):
                try:
                    page = doc[page_num]
                    text += page.get_text()
                    if (page_num + 1) % 50 == 0:
                        print(f"      Progress: {page_num + 1}/{page_count} pages")
                except Exception as page_error:
                    print(f"      âš ï¸ Page {page_num + 1} ì—ëŸ¬, ìŠ¤í‚µ: {str(page_error)[:50]}")
                    continue
            
            doc.close()
            
        except Exception as extraction_error:
            print(f"   âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(extraction_error)[:100]}")
            return None
        
        if not text or len(text.strip()) < 10:
            print(f"   âš ï¸ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return None
        
        print(f"   âœ… {len(text):,} ë¬¸ì ì¶”ì¶œ ({page_count} í˜ì´ì§€)")
        
        # 2. ì²­í¬ ë¶„í• 
        chunk_size = 3000
        chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]
        
        # ëŒ€ìš©ëŸ‰ PDFëŠ” ì²­í¬ ìˆ˜ ì œí•œ (ë¹„ìš© ì ˆê°)
        max_chunks = 50
        if len(chunks) > max_chunks:
            print(f"   âš ï¸ ì²­í¬ ìˆ˜ ì œí•œ: {len(chunks)} â†’ {max_chunks} (ë¹„ìš© ì ˆê°)")
            chunks = chunks[:max_chunks]
        
        print(f"   ğŸ“¦ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")
        
        # 3. OpenAIë¡œ ì—”í‹°í‹° ì¶”ì¶œ
        print(f"   ğŸ¤– GPT-4o-minië¡œ ì—”í‹°í‹° ì¶”ì¶œ ì¤‘...")
        client = AsyncOpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
        
        all_entities = []
        all_relationships = []
        
        for i, chunk in enumerate(chunks, 1):
            if i % 10 == 0 or i == 1:
                print(f"      Progress: {i}/{len(chunks)} chunks ({i*100//len(chunks)}%)")
            
            prompt = f"""Extract business entities and relationships from this semiconductor/financial text.
Return ONLY valid JSON format:

{{
  "entities": [
    {{"name": "EntityName", "type": "COMPANY|PERSON|PRODUCT|TECHNOLOGY|FINANCIAL_METRIC|LOCATION|REGULATION|RISK", "properties": {{"key": "value"}}}}
  ],
  "relationships": [
    {{"source": "EntityA", "target": "EntityB", "type": "RELATIONSHIP_TYPE", "properties": {{"key": "value"}}}}
  ]
}}

Entity types: COMPANY, PERSON, PRODUCT, TECHNOLOGY, FINANCIAL_METRIC, LOCATION, REGULATION, RISK, MARKET, SUPPLY_CHAIN
Relationship types: SUPPLIES, PURCHASES, COMPETES_WITH, HAS_CEO, EMPLOYS, LOCATED_IN, PRODUCES, IMPACTS, DEPENDS_ON, REGULATES

Text:
{chunk}

JSON output:"""
            
            try:
                response = await client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "You are a financial document analyzer. Extract structured entities and relationships. Respond with valid JSON only."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,
                    max_tokens=2000,
                    timeout=30
                )
                
                content = response.choices[0].message.content.strip()
                
                # JSON íŒŒì‹±
                if content.startswith("```json"):
                    content = content[7:]
                if content.startswith("```"):
                    content = content[3:]
                if content.endswith("```"):
                    content = content[:-3]
                content = content.strip()
                
                extracted = json.loads(content)
                all_entities.extend(extracted.get("entities", []))
                all_relationships.extend(extracted.get("relationships", []))
                
            except Exception as e:
                print(f"      âš ï¸ Chunk {i} ì‹¤íŒ¨: {str(e)[:50]}")
                continue
        
        print(f"   âœ… ì´ {len(all_entities)} ì—”í‹°í‹°, {len(all_relationships)} ê´€ê³„ ì¶”ì¶œ")
        
        # ì—”í‹°í‹° ìƒ˜í”Œ ì¶œë ¥
        if all_entities:
            print(f"   ğŸ“‹ ì¶”ì¶œëœ ì—”í‹°í‹° ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):")
            for ent in all_entities[:5]:
                print(f"      - {ent.get('name')} ({ent.get('type')})")
        
        # 4. Neo4jì— ì €ì¥
        print(f"   ğŸ’¾ Neo4jì— ì €ì¥ ì¤‘...")
        integrator = DataIntegrator()
        graph_data = {
            "entities": all_entities,
            "relationships": all_relationships
        }
        
        merge_stats = integrator.ingestPdfGraph(
            graphData=graph_data,
            sourceFile=pdf_path.name,
            sourceLabel=pdf_path.stem
        )
        integrator.close()
        
        print(f"   âœ… Neo4j ì €ì¥ ì™„ë£Œ:")
        print(f"      - ë³‘í•©ëœ ì—”í‹°í‹°: {merge_stats.get('entitiesMerged', 0):,}")
        print(f"      - ìƒì„±ëœ ê´€ê³„: {merge_stats.get('relationshipsCreated', 0):,}")
        
        return {
            'file': pdf_path.name,
            'text_length': len(text),
            'entities': len(all_entities),
            'relationships': len(all_relationships),
            'merged': merge_stats
        }
        
    except Exception as e:
        print(f"   âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    start_time = datetime.now()
    
    print("=" * 70)
    print("ğŸš€ Baseline PDF íŒŒì¼ë“¤ì„ Neo4jì— ì˜êµ¬ ì €ì¥")
    print("=" * 70)
    print(f"ì‹œì‘ ì‹œê°„: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ì„¤ì • í™•ì¸
    if not NEO4J_URI or not NEO4J_PASSWORD:
        print("âŒ Neo4j ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    if not OPENAI_API_KEY:
        print("âŒ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)
    
    # Neo4j ì—°ê²°
    db = Neo4jDatabase(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)
    print(f"âœ… Neo4j ì—°ê²° ì„±ê³µ: {NEO4J_URI}")
    
    # PDF íŒŒì¼ ëª©ë¡ (í¬ê¸° ìˆœìœ¼ë¡œ ì •ë ¬ - ì‘ì€ ê²ƒë¶€í„°)
    data_dir = Path(__file__).parent / 'data' / 'baseline'
    pdf_files = sorted(data_dir.glob('*.pdf'), key=lambda p: p.stat().st_size)
    
    if not pdf_files:
        print("âŒ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    print(f"\nğŸ“š ë°œê²¬ëœ PDF íŒŒì¼: {len(pdf_files)}ê°œ")
    for i, pdf in enumerate(pdf_files, 1):
        size_kb = pdf.stat().st_size / 1024
        print(f"   {i}. {pdf.name} ({size_kb:.1f} KB)")
    
    # ê° PDF ì²˜ë¦¬
    results = []
    
    for i, pdf_file in enumerate(pdf_files, 1):
        print(f"\n\n{'='*70}")
        print(f"ì§„í–‰ ìƒí™©: {i}/{len(pdf_files)} ({i*100//len(pdf_files)}%)")
        print(f"{'='*70}")
        
        result = await process_pdf_to_neo4j(pdf_file, db)
        if result:
            results.append(result)
    
    # ìµœì¢… í†µê³„
    print(f"\n\n{'='*70}")
    print("ğŸ“Š ìµœì¢… í†µê³„")
    print(f"{'='*70}")
    
    # ì²˜ë¦¬ëœ íŒŒì¼ í†µê³„
    print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ: {len(results)}/{len(pdf_files)} íŒŒì¼")
    
    total_entities = sum(r['entities'] for r in results)
    total_relationships = sum(r['relationships'] for r in results)
    
    print(f"   - ì´ ì¶”ì¶œëœ ì—”í‹°í‹°: {total_entities:,}")
    print(f"   - ì´ ì¶”ì¶œëœ ê´€ê³„: {total_relationships:,}")
    
    # Neo4j ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
    print(f"\nğŸ“ˆ Neo4j ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:")
    
    # ë…¸ë“œ íƒ€ì…ë³„
    node_stats = db.execute_query("""
        MATCH (n)
        RETURN labels(n)[0] as type, count(n) as count
        ORDER BY count DESC
        LIMIT 10
    """)
    
    print(f"\n   ë…¸ë“œ íƒ€ì… (Top 10):")
    total_nodes = 0
    for record in node_stats:
        count = record['count']
        total_nodes += count
        print(f"   - {record['type']}: {count:,}")
    
    # ê´€ê³„ íƒ€ì…ë³„
    rel_stats = db.execute_query("""
        MATCH ()-[r]->()
        RETURN type(r) as type, count(r) as count
        ORDER BY count DESC
        LIMIT 10
    """)
    
    print(f"\n   ê´€ê³„ íƒ€ì… (Top 10):")
    total_rels = 0
    for record in rel_stats:
        count = record['count']
        total_rels += count
        print(f"   - {record['type']}: {count:,}")
    
    print(f"\n   ğŸ“Š ì´ ë…¸ë“œ ìˆ˜: {total_nodes:,}")
    print(f"   ğŸ”— ì´ ê´€ê³„ ìˆ˜: {total_rels:,}")
    
    db.close()
    
    # ì†Œìš” ì‹œê°„
    end_time = datetime.now()
    duration = end_time - start_time
    
    print(f"\n{'='*70}")
    print("âœ… ëª¨ë“  PDF íŒŒì¼ì´ Neo4jì— ì˜êµ¬ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"{'='*70}")
    print(f"ì¢…ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ì†Œìš” ì‹œê°„: {duration}")
    print(f"\nğŸ’¡ ì„¸ì…˜ì„ ì¢…ë£Œí•´ë„ ë°ì´í„°ê°€ Neo4jì— ìœ ì§€ë©ë‹ˆë‹¤.")
    print(f"ğŸ’¡ Streamlit UIì˜ Visualization íƒ­ì—ì„œ ê·¸ë˜í”„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    print(f"{'='*70}")


if __name__ == "__main__":
    asyncio.run(main())
